{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nahyun-hong/miniconda3/envs/myenv/lib/python3.11/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage, trim_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    SystemMessage(content=\"system\"),\n",
    "    HumanMessage(content=\"Human1\"),\n",
    "    AIMessage(content=\"AI1\"),\n",
    "    HumanMessage(content=\"Human2\"),\n",
    "    AIMessage(content=\"AI2\"),\n",
    "    HumanMessage(content=\"Human3\"),\n",
    "    AIMessage(content=\"AI3\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='system', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Human1', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='AI1', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Human2', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='AI2', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Human3', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='AI3', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 대화 많이 남기기\n",
    "trimer = trim_messages(\n",
    "    max_tokens=1000,\n",
    "    token_counter=llm\n",
    ")\n",
    "\n",
    "trimer.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Human2', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='AI2', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Human3', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='AI3', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 대화 적게 남기기\n",
    "trimer = trim_messages(\n",
    "    max_tokens=30,\n",
    "    token_counter=llm\n",
    ")\n",
    "\n",
    "trimer.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='system', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Human1', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='AI1', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Human2', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 과거 대화를 남기고 최근 대화를 지우기\n",
    "trimer = trim_messages(\n",
    "    max_tokens=30,\n",
    "    token_counter=llm,\n",
    "    strategy=\"first\"\n",
    ")\n",
    "\n",
    "trimer.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Human2', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='AI2', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Human3', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='AI3', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 최근 대화를 남기고 과거 대화를 지우기\n",
    "trimer = trim_messages(\n",
    "    max_tokens=30,\n",
    "    token_counter=llm,\n",
    "    strategy=\"last\"\n",
    ")\n",
    "\n",
    "trimer.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='system', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='AI2', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Human3', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='AI3', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 최근 대화를 남기고 과거 대화를 지우는데 시스템 메시지 남기기\n",
    "trimer = trim_messages(\n",
    "    max_tokens=30,\n",
    "    token_counter=llm,\n",
    "    strategy=\"last\",\n",
    "    include_system=True\n",
    ")\n",
    "\n",
    "trimer.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='system', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Human3', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='AI3', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 최근 대화를 남기고 과거 대화를 지우는데 시스템 메시지 남기고 Human Message 부터 시작하기\n",
    "trimer = trim_messages(\n",
    "    max_tokens=30,\n",
    "    token_counter=llm,\n",
    "    strategy=\"last\",\n",
    "    include_system=True,\n",
    "    start_on=\"human\"\n",
    ")\n",
    "\n",
    "trimer.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    SystemMessage(content=\"사용자의 질문에 2문장 이내로 짧게 대답해\"),\n",
    "    HumanMessage(content=\"오늘은 피자를 먹어야지!\"),\n",
    "    AIMessage(content=\"정말 좋은 생각이야. 음료는 무엇으로 할거야?\"),\n",
    "    HumanMessage(content=\"내일은 수영을 가야지!\"),\n",
    "    AIMessage(content=\"수영이라니 정말 종은 운동이야. 수영장은 어디로 다녀?\"),\n",
    "    HumanMessage(content=\"주말에는 영화를 보러갈거야!\"),\n",
    "    AIMessage(content=\"주말이 벌써부터 기다려지겠는걸? 보려고 생각해둔 영화가 있어?\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trimmer = trim_messages(\n",
    "    max_tokens=120,\n",
    "    token_counter=llm,\n",
    "    strategy=\"last\",\n",
    "    include_system=True,\n",
    "    start_on=\"human\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='사용자의 질문에 2문자 이내로 짧게 대답해', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='내일은 수영을 가야지!', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='수영이라니 정말 종은 운동이야. 수영장은 어디로 다녀?', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='주말에는 영화를 보러갈거야!', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='주말이 벌써부터 기다려지겠는걸? 보려고 생각해둔 영화가 있어?', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trimmer.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "parser = StrOutputParser()\n",
    "\n",
    "chain = trimmer | llm | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:trim_messages] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:trim_messages] [4ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: 사용자의 질문에 2문장 이내로 짧게 대답해\\nHuman: 내일은 수영을 가야지!\\nAI: 수영이라니 정말 종은 운동이야. 수영장은 어디로 다녀?\\nHuman: 주말에는 영화를 보러갈거야!\\nAI: 주말이 벌써부터 기다려지겠는걸? 보려고 생각해둔 영화가 있어?\\nHuman: 오늘 뭘 먹는다고 했지?\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOpenAI] [1.51s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"아직 정하지 않았어요! 무엇인가 추천해줄까요?\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"아직 정하지 않았어요! 무엇인가 추천해줄까요?\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"refusal\": null\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 14,\n",
      "                \"prompt_tokens\": 117,\n",
      "                \"total_tokens\": 131,\n",
      "                \"completion_tokens_details\": {\n",
      "                  \"accepted_prediction_tokens\": 0,\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"reasoning_tokens\": 0,\n",
      "                  \"rejected_prediction_tokens\": 0\n",
      "                },\n",
      "                \"prompt_tokens_details\": {\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"cached_tokens\": 0\n",
      "                }\n",
      "              },\n",
      "              \"model_name\": \"gpt-4o-mini-2024-07-18\",\n",
      "              \"system_fingerprint\": \"fp_62a23a81ef\",\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run--0069903f-f296-43a5-b72b-1ff78807e214-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 117,\n",
      "              \"output_tokens\": 14,\n",
      "              \"total_tokens\": 131,\n",
      "              \"input_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"cache_read\": 0\n",
      "              },\n",
      "              \"output_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"reasoning\": 0\n",
      "              }\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 14,\n",
      "      \"prompt_tokens\": 117,\n",
      "      \"total_tokens\": 131,\n",
      "      \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "      },\n",
      "      \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "      }\n",
      "    },\n",
      "    \"model_name\": \"gpt-4o-mini-2024-07-18\",\n",
      "    \"system_fingerprint\": \"fp_62a23a81ef\"\n",
      "  },\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:StrOutputParser] [1ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"아직 정하지 않았어요! 무엇인가 추천해줄까요?\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence] [1.51s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"아직 정하지 않았어요! 무엇인가 추천해줄까요?\"\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'아직 정하지 않았어요! 무엇인가 추천해줄까요?'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(messages + [\n",
    "    HumanMessage(content=\"오늘 뭘 먹는다고 했지?\")\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:trim_messages] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:trim_messages] [4ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: 사용자의 질문에 2문장 이내로 짧게 대답해\\nHuman: 주말에는 영화를 보러갈거야!\\nAI: 주말이 벌써부터 기다려지겠는걸? 보려고 생각해둔 영화가 있어?\\nHuman: 주말에 내가 뭐하러 간다고 했지?\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOpenAI] [1.10s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"주말에 영화를 보러 간다고 했어! 어떤 영화를 볼 예정이야?\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"주말에 영화를 보러 간다고 했어! 어떤 영화를 볼 예정이야?\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"refusal\": null\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 20,\n",
      "                \"prompt_tokens\": 82,\n",
      "                \"total_tokens\": 102,\n",
      "                \"completion_tokens_details\": {\n",
      "                  \"accepted_prediction_tokens\": 0,\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"reasoning_tokens\": 0,\n",
      "                  \"rejected_prediction_tokens\": 0\n",
      "                },\n",
      "                \"prompt_tokens_details\": {\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"cached_tokens\": 0\n",
      "                }\n",
      "              },\n",
      "              \"model_name\": \"gpt-4o-mini-2024-07-18\",\n",
      "              \"system_fingerprint\": \"fp_34a54ae93c\",\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run--17de3b9a-95aa-4194-9bde-ab447a9f5b25-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 82,\n",
      "              \"output_tokens\": 20,\n",
      "              \"total_tokens\": 102,\n",
      "              \"input_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"cache_read\": 0\n",
      "              },\n",
      "              \"output_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"reasoning\": 0\n",
      "              }\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 20,\n",
      "      \"prompt_tokens\": 82,\n",
      "      \"total_tokens\": 102,\n",
      "      \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "      },\n",
      "      \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "      }\n",
      "    },\n",
      "    \"model_name\": \"gpt-4o-mini-2024-07-18\",\n",
      "    \"system_fingerprint\": \"fp_34a54ae93c\"\n",
      "  },\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:StrOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"주말에 영화를 보러 간다고 했어! 어떤 영화를 볼 예정이야?\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence] [1.11s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"주말에 영화를 보러 간다고 했어! 어떤 영화를 볼 예정이야?\"\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'주말에 영화를 보러 간다고 했어! 어떤 영화를 볼 예정이야?'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(messages + [\n",
    "    HumanMessage(content=\"주말에 내가 뭐하러 간다고 했지?\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "langchain.debug = True"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyhton (conda-myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
